{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing IP Patent Grant Data\n",
    "\n",
    "**Author:** Salman Tahir  \n",
    "**Environment:** Conda 23.7.2, Python 3.10.12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>\n",
    "\n",
    "-   [Introduction](#toc2_)\n",
    "-   [Importing Libraries](#toc3_)\n",
    "-   [Examining Patent Files](#toc4_)\n",
    "    -   [Structure of the Data](#toc4_1_)\n",
    "    -   [Identifying Patterns in Data](#toc4_2_)\n",
    "-   [Loading and Parsing Files](#toc5_)\n",
    "    -   [Defining Regular Expressions](#toc5_1_)\n",
    "    -   [Preparing the Data](#toc5_2_)\n",
    "    -   [Parsing the Data](#toc5_3_)\n",
    "    -   [Creating a DataFrame](#toc5_4_)\n",
    "-   [Outputting Files](#toc6_)\n",
    "    -   [Writing to CSV](#toc6_1_)\n",
    "    -   [Writing to JSON](#toc6_2_)\n",
    "    -   [Verifying Outputs](#toc6_3_)\n",
    "-   [Summary](#toc7_)\n",
    "-   [References](#toc8_)\n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=2\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Introduction](#toc0_)\n",
    "\n",
    "In this project, we parse and pre-process a raw text file to prepare it for downstream analysis.\n",
    "\n",
    "-   The objective is to extract data from the dataset containing information about grants given for Intellectual Property (IP) patent claims.\n",
    "-   Regular expressions are used for pattern matching and extraction of relevant data from the text file.\n",
    "-   The resulting data is then output to CSV and JSON file formats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Importing Libraries](#toc0_)\n",
    "\n",
    "The following libraries are imported:\n",
    "\n",
    "-   `re`: to define and use regular expressions for pattern matching.\n",
    "-   `pandas`: to create DataFrame objects and manipulate data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Examining Patent Files](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_1_'></a>[Structure of the Data](#toc0_)\n",
    "\n",
    "The first step is to examine our text file and understand the structure of the data.\n",
    "\n",
    "From visual inspection of the data, we can conclude the following:\n",
    "\n",
    "-   The XML declaration on the first line tells us, the text file contains XML data with an encoding of `UTF-8`.\n",
    "-   We can see the XML declaration: `<?xml version=\"1.0\" encoding=\"UTF-8\"?>` occurs multiple times in the data.\n",
    "-   This tells us the text file contains multiple XML documents, where each document is separated by the XML declaration.\n",
    "\n",
    "Therefore, we define a function called `count_xml_docs` to count the number of XML documents in the text file.\n",
    "\n",
    "-   The function argument is the path to our text file.\n",
    "-   We separate the XML documents by the XML declaration.\n",
    "-   We then count and return the number of documents in the text file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to our text file\n",
    "FILE_PATH = '../data/input/patent_grants_data.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of XML documents: 150\n"
     ]
    }
   ],
   "source": [
    "def count_xml_docs(file_path):\n",
    "    \"\"\"\n",
    "    Reads the text file returns the number of XML documents in the file.\n",
    "    :param file_path: path to assignment text file\n",
    "    :return: number of XML documents in the text file\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        docs = text.split('<?xml version=\"1.0\" encoding=\"UTF-8\"?>')[1:]\n",
    "\n",
    "    return len(docs)\n",
    "\n",
    "\n",
    "# Path to our text file\n",
    "num_docs = count_xml_docs(FILE_PATH)\n",
    "\n",
    "# Print the number of XML documents in the text file\n",
    "print(f'Total number of XML documents: {num_docs}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_2_'></a>[Identifying Patterns in Data](#toc0_)\n",
    "\n",
    "Now that we have a better understanding of the structure of our dataset, we can look into the data to identify the information we need to extract.\n",
    "\n",
    "We are given the following information about the data we need to extract:\n",
    "\n",
    "1. **grant_id**: a unique ID for a patent grant consisting of alphanumeric characters.\n",
    "2. **patent_kind**: a category to which the patent grant belongs.\n",
    "3. **patent_title**: a title given by the inventor(s) to the patent claim.\n",
    "4. **number_of_claims**: an integer denoting the number of claims for a given grant.\n",
    "5. **citations_examiner_count**: an integer denoting the number of citations made by the\n",
    "   examiner for a given patent grant (use 0 if None).\n",
    "6. **citations_applicant_count**: an integer denoting the number of citations made by the\n",
    "   applicant for a given patent grant (use 0 if None).\n",
    "7. **inventors**: a list of the patent inventors’ names (use [NA] if the value is Null).\n",
    "8. **claims_text**: a list of claim texts for the different patent claims (use [NA] if the value\n",
    "   is Null).\n",
    "9. **abstract**: the patent abstract text (use ‘NA’ if the value is Null).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the `grant_id`\n",
    "\n",
    "By looking at the XML documents in the text file we can conclude the following:\n",
    "\n",
    "-   The XML document contains a root element `<us-patent-grant>`.\n",
    "-   The root element has a set of attributes of which the one we are interested in has the format `file=\"US10361423-20190723.XML\"`.\n",
    "\n",
    "By examining the sample files and using the information we have gathered so far, we can identify the `grant_id` in the `file` attribute of the root element `<us-patent-grant>`.\n",
    "\n",
    "The format of the ID is `CC-<8-digit number>-<date>` <sup>[1]</sup> where:\n",
    "\n",
    "-   The `CC` is a two-letter ISO country code.\n",
    "-   The `<8-digit number>` is the patent number. <sup>[2]</sup>\n",
    "    -   The patent number may include up to eight characters, depending on the type of patent.\n",
    "    -   For example, a utility patent number may include up to eight characters, whereas a Reissue patent number includes `RE` followed by 6 digits. Therefore, we need to account for this in our regular expression.\n",
    "-   The `<4-digit year>-<2-digit month>-<2-digit day>` is assumed to be the date on which the patent was granted.\n",
    "\n",
    "Now, by examining the sample outputs provided, we can identify that we only require the `CC-<8-digit number>` part of the `file` attribute therefore, we can use the following regular expression to extract the `grant_id`:\n",
    "\n",
    "```python\n",
    "r'<us-patent-grant.*?file=\"([A-Z]{2}(?:[A-Z]{1,2})?\\d+).*?\\.XML\".*?>'\n",
    "```\n",
    "\n",
    "**Explanation of the regular expression:**\n",
    "\n",
    "-   `<us-patent-grant.*?>`: matches the opening tag of the root element `<us-patent-grant>`.\n",
    "-   `.*?`: matches any characters between the opening tag of the root element and the `file` attribute.\n",
    "-   `file=\"`: matches the `file` attribute.\n",
    "-   `([A-Z]{2}(?:[A-Z]{1,2})?\\d+)`: our capturing group that matches the `CC-<8-digit number>` part of the `file` attribute.\n",
    "    -   Here, using a non-capturing group, we also account that the 8 digit number may include some characters depending on the type of patent.\n",
    "-   `.*?`: matches any characters between the `CC-<8-digit number>` part of the `file` attribute and the `.XML\"` part of the `file` attribute.\n",
    "-   `\\.XML\"`: is a literal match of the `.XML\"` part of the `file` attribute.\n",
    "-   `.*?>`: matches any characters between the `.XML\"` part of the `file` attribute and the closing tag of the root element `<us-patent-grant>`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the `patent_kind` or `kind`\n",
    "\n",
    "By observing the sample outputs provided, we can conclude that the `patent_kind` is the value of the `kind` tag located inside the tag `<publication-reference>` element.\n",
    "\n",
    "Although, there are a few things to note:\n",
    "\n",
    "-   In the sample output, the `patent_kind` attribute column is named as `kind` therefore we will use the same name as in the sample output to avoid confusion.\n",
    "-   Secondly, in the sample output provided, the value of the `kind` tag is not a code but a description of the patent kind therefore, we will reference the IP Australia website to identify the USPTO kind codes for each patent kind. <sup>[3]</sup>\n",
    "\n",
    "Hence, we can use the following regular expression to extract the `kind`:\n",
    "\n",
    "```python\n",
    "r'<publication-reference>.*?<kind>(\\w{1,2})</kind>.*?</publication-reference>'\n",
    "```\n",
    "\n",
    "**Explanation of the regular expression:**\n",
    "\n",
    "-   `<publication-reference>`: matches the opening tag of the `<publication-reference>` element.\n",
    "-   `.*?`: matches any characters between the opening tag of the `<publication-reference>` element and the `<kind>` tag.\n",
    "-   `<kind>`: matches the opening tag of the `<kind>` tag.\n",
    "-   `(\\w{1,2})`: our capturing group that matches the value of the `<kind>` tag.\n",
    "    -   Note that we have identified the value of the `<kind>` tag can be a maximum of 2 characters and a minimum of 1 character.\n",
    "-   `</kind>`: matches the closing tag of the `<kind>` tag.\n",
    "-   `.*?`: matches any characters between the closing tag of the `<kind>` tag and the closing tag of the `<publication-reference>` element.\n",
    "-   `</publication-reference>`: matches the closing tag of the `<publication-reference>` element.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the `patent_title`\n",
    "\n",
    "By observing the sample input and output files we can conclude that the `patent_title` is the value of the `<invention-title>` element.\n",
    "\n",
    "Although, there are a few things to note:\n",
    "\n",
    "-   Any HTML entities present in the title need to be decoded to their unicode equivalent or be removed.\n",
    "-   These changes will be accounted for in the statement for the `patent_title`.\n",
    "\n",
    "Hence, we can use the following regular expression to extract the `patent_title`:\n",
    "\n",
    "```python\n",
    "r'<invention-title id=\\\".*?\\\">(.*?)</invention-title>'\n",
    "```\n",
    "\n",
    "**Explanation of the regular expression:**\n",
    "\n",
    "-   `<invention-title id=\".*?\">`: matches the opening tag of the `<invention-title>` element.\n",
    "    -   Note that we are not interested in capturing the value of the `id` attribute.\n",
    "-   `(.*?)`: our capturing group that matches the value of the `<invention-title>` tag.\n",
    "-   `</invention-title>`: matches the closing tag of the `<invention-title>` element.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the `number_of_claims`\n",
    "\n",
    "By observing the sample input and output files we can conclude the following:\n",
    "\n",
    "-   The `number_of_claims` is the value of the `<number-of-claims>` element.\n",
    "-   The `<number-of-claims>` value is an integer.\n",
    "\n",
    "Hence, we can use the following regular expression to extract the `number_of_claims`:\n",
    "\n",
    "```python\n",
    "r'<number-of-claims>(\\d+)</number-of-claims>'\n",
    "```\n",
    "\n",
    "**Explanation of the regular expression:**\n",
    "\n",
    "-   `<number-of-claims>`: matches the opening tag of the `<number-of-claims>` element.\n",
    "-   `(\\d+)`: our capturing group that matches the value of the `<number-of-claims>` tag.\n",
    "-   `</number-of-claims>`: matches the closing tag of the `<number-of-claims>` element.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the `citations_examiner_count`\n",
    "\n",
    "By observing the sample files and our input file we can conclude the following:\n",
    "\n",
    "-   There is no specific count given for the number of citations broken down by examiner.\n",
    "-   To get the count of citations by examiner we search for all occurrences of the `<category>` element with a value of `\"cited by examiner\"`\n",
    "\n",
    "Hence, we can use the following regular expression to extract the `citations_examiner_count`:\n",
    "\n",
    "```python\n",
    "r'<category>cited by examiner<\\/category>'\n",
    "```\n",
    "\n",
    "**Explanation of the regular expression:**\n",
    "\n",
    "-   `<category>`: matches the opening tag of the `<category>` element.\n",
    "-   `cited by examiner`: matches the value of the `<category>` element.\n",
    "-   `</category>`: matches the closing tag of the `<category>` element.\n",
    "\n",
    "We will then use the len() function to count the number of times the regular expression matches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the `citations_applicant_count`\n",
    "\n",
    "Similarly to the `citations_examiner_count`, we can conclude the following from observing the sample files and our input file:\n",
    "\n",
    "-   There is no specific count given for the number of citations broken down by applicant.\n",
    "-   To get the count of citations by applicant we search for all occurrences of the `<category>` element with a value of `\"cited by applicant\"`\n",
    "\n",
    "Hence, we can use the following regular expression to extract the `citations_applicant_count`:\n",
    "\n",
    "```python\n",
    "r'<category>cited by applicant<\\/category>'\n",
    "```\n",
    "\n",
    "**Explanation of the regular expression:**\n",
    "\n",
    "-   `<category>`: matches the opening tag of the `<category>` element.\n",
    "-   `cited by applicant`: matches the value of the `<category>` element.\n",
    "-   `</category>`: matches the closing tag of the `<category>` element.\n",
    "\n",
    "We will then use the len() function to count the number of times the regular expression matches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the `inventors`\n",
    "\n",
    "By observing the sample input and output files we conclude the following:\n",
    "\n",
    "-   `inventors` is a list of the patent inventors' names.\n",
    "-   In the sample output, the format is `\"[<first name> <last name>,<first name> <last name>,...]\"`\n",
    "\n",
    "Therefore, we first extract all information in the `<inventors>` element using the following regular expression:\n",
    "\n",
    "```python\n",
    "r'<inventors>.*?</inventors>'\n",
    "```\n",
    "\n",
    "**Explanation of the regular expression:**\n",
    "\n",
    "-   `<inventors>`: matches the opening tag of the `<inventors>` element.\n",
    "-   `.*?`: matches any characters between the opening tag of the `<inventors>` element and the closing tag of the `<inventors>` element.\n",
    "-   `</inventors>`: matches the closing tag of the `<inventors>` element.\n",
    "\n",
    "Then, we use the following regular expressions to extract the `first_name` and `last_name` from within the `<addressbook>` element inside the parent `<inventor>` element:\n",
    "\n",
    "```python\n",
    "r'<inventor[^>]*>\\s*<addressbook>\\s*<last-name>([^<]*)<\\/last-name>\\s*<first-name>([^<]*)<\\/first-name>'\n",
    "```\n",
    "\n",
    "**Explanation of the regular expression:**\n",
    "\n",
    "-   `<inventor[^>]*>`: matches the opening tag of the `<inventor>` element.\n",
    "-   `\\s*`: matches any whitespace characters.\n",
    "-   `<addressbook>`: matches the opening tag of the `<addressbook>` element.\n",
    "-   `\\s*`: matches any whitespace characters.\n",
    "-   `<last-name>`: matches the opening tag of the `<last-name>` element.\n",
    "-   `([^<]*)`: our first capturing group that matches the value of the `<last-name>` tag.\n",
    "-   `</last-name>`: matches the closing tag of the `<last-name>` element.\n",
    "-   `\\s*`: matches any whitespace characters.\n",
    "-   `<first-name>`: matches the opening tag of the `<first-name>` element.\n",
    "-   `([^<]*)`: our second capturing group that matches the value of the `<first-name>` tag.\n",
    "-   `</first-name>`: matches the closing tag of the `<first-name>` element.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the `claims_text`\n",
    "\n",
    "Each XML document in the text file has a `<claims>` element inside which there can be multiple `<claim-text>` elements.\n",
    "We can first extract all occurrences of the `<claims>` element along with its contents using the following regular expression:\n",
    "\n",
    "```python\n",
    "r'<claims id=\"claims\">.*?<\\/claims>'\n",
    "```\n",
    "\n",
    "**Explanation of the regular expression:**\n",
    "\n",
    "-   `<claims id=\"claims\">`: matches the opening tag of the `<claims>` element.\n",
    "-   `.*?`: matches any characters between the opening tag of the `<claims>` element and the closing tag of the `<claims>` element.\n",
    "-   `</claims>`: matches the closing tag of the `<claims>` element.\n",
    "\n",
    "The resulting list consists of all non-overlapping matches of the regular expression, which gives us a list of strings containing the `<claims>` element and its contents. Now, for each string in the list, we can extract the `<claim-text>` element using the following regular expression:\n",
    "\n",
    "```python\n",
    "r'<claim-text>(.*?)<\\/claim-text>'\n",
    "```\n",
    "\n",
    "**Explanation of the regular expression:**\n",
    "\n",
    "-   `<claim-text>`: matches the opening tag of the `<claim-text>` element.\n",
    "-   `(.*?)`: our capturing group that matches the value of the `<claim-text>` tag.\n",
    "-   `</claim-text>`: matches the closing tag of the `<claim-text>` element.\n",
    "\n",
    "Finally, we can use list comprehension to apply the second regular expression to each string in the list obtained from the first regular expression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the `abstract`\n",
    "\n",
    "By observing the sample input and output files we know:\n",
    "\n",
    "-   The abstract is the value contained within the `<abstract>` element.\n",
    "-   The abstract is a single string.\n",
    "-   The abstract is not always present in the XML document, therefore we can use NA to represent the absence of the abstract.\n",
    "\n",
    "Hence, we can use the following regular expression to extract the `abstract`:\n",
    "\n",
    "```python\n",
    "r'<abstract[^>]*>\\s*<p[^>]*>(.*?)<\\/p>\\s*<\\/abstract>'\n",
    "```\n",
    "\n",
    "**Explanation of the regular expression:**\n",
    "\n",
    "-   `<abstract[^>]*>`: matches the opening tag of the `<abstract>` element.\n",
    "    -   The inclusion of [^>]\\* indicates that it matches any number of characters that are not `>` between the opening `<abstract` tag and the closing `>` of that tag\n",
    "-   `\\s*`: matches any whitespace characters.\n",
    "-   `<p[^>]*>`: matches the opening tag of the `<p>` element.\n",
    "    -   The inclusion of [^>]\\* indicates that it matches any number of characters that are not `>` between the opening `<p` tag and the closing `>` of that tag\n",
    "-   `(.*?)`: our capturing group that matches the value of the `<p>` tag.\n",
    "-   `</p>`: matches the closing tag of the `<p>` element.\n",
    "-   `\\s*`: matches any whitespace characters.\n",
    "-   `</abstract>`: matches the closing tag of the `<abstract>` element.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Loading and Parsing Files](#toc0_)\n",
    "\n",
    "Now that we have identified the regular expressions required to extract the information from the text file for each of the attributes, we can start with the actual parsing of the text file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_1_'></a>[Defining Regular Expressions](#toc0_)\n",
    "\n",
    "Here, we define the regular expressions, identified in the previous section, as variables.\n",
    "\n",
    "We use `re.compile()` to compile the regular expressions into pattern objects, which is a more efficient way of using regular expressions in since Python won't need to recompile the regular expressions each time they are used in the loop.\n",
    "\n",
    "We will use UPPER_CASE for the names of the regular expressions to indicate that they are constants as per the Python naming convention. <sup>[4]</sup>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex for extracting the grant ID\n",
    "GRANT_ID_PATTERN = re.compile(\n",
    "    r'<us-patent-grant.*?file=\"([A-Z]{2}(?:[A-Z]{1,2})?\\d+).*?\\.XML\".*?>', flags=re.DOTALL)\n",
    "\n",
    "# Regex for extracting the patent kind\n",
    "KIND_PATTERN = re.compile(\n",
    "    r'<publication-reference>.*?<kind>(\\w{1,2})</kind>.*?</publication-reference>', flags=re.DOTALL)\n",
    "\n",
    "# Regex for extracting the patent title\n",
    "PATENT_TITLE_PATTERN = re.compile(\n",
    "    r'<invention-title id=\\\".*?\\\">(.*?)</invention-title>', flags=re.DOTALL)\n",
    "\n",
    "# Regex for extracting the number of claims\n",
    "NUMBER_OF_CLAIMS_PATTERN = re.compile(\n",
    "    r'<number-of-claims>(\\d+)</number-of-claims>', flags=re.DOTALL)\n",
    "\n",
    "# Regex for extracting the citations by examiner\n",
    "CITATIONS_EXAMINER_COUNT_PATTERN = re.compile(\n",
    "    r'<category>cited by examiner<\\/category>', flags=re.DOTALL)\n",
    "\n",
    "# Regex for extracting the citations by applicant\n",
    "CITATIONS_APPLICANT_COUNT_PATTERN = re.compile(\n",
    "    r'<category>cited by applicant<\\/category>', flags=re.DOTALL)\n",
    "\n",
    "# Regex for extracting all information in the <inventors> tag\n",
    "INVENTORS_TAG_PATTERN = re.compile(\n",
    "    r'<inventors>.*?</inventors>', flags=re.DOTALL)\n",
    "\n",
    "# Regex for extracting the inventors' names\n",
    "INVENTORS_PATTERN = re.compile(\n",
    "    r'<inventor[^>]*>\\s*<addressbook>\\s*<last-name>([^<]*)<\\/last-name>\\s*<first-name>([^<]*)<\\/first-name>', flags=re.DOTALL)\n",
    "\n",
    "# Regex for extracting all information in the <claims> tag\n",
    "CLAIMS_TAG_PATTERN = re.compile(\n",
    "    r'<claims id=\"claims\">.*?<\\/claims>', flags=re.DOTALL)\n",
    "\n",
    "# Regex for extracting the claims text\n",
    "CLAIMS_TEXT_PATTERN = re.compile(\n",
    "    r'<claim-text>(.*?)<\\/claim-text>', flags=re.DOTALL)\n",
    "\n",
    "# Regex for extracting the abstracts\n",
    "ABSTRACT_PATTERN = re.compile(\n",
    "    r'<abstract[^>]*>\\s*<p[^>]*>(.*?)<\\/p>\\s*<\\/abstract>', flags=re.DOTALL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_2_'></a>[Preparing the Data](#toc0_)\n",
    "\n",
    "We define a function `clean_xml_docs()` that takes our text file as input and returns a list of cleaned XML documents. We achieve this in the following steps:\n",
    "\n",
    "-   The function opens the file at the specified path (`FILE_PATH`) which we defined at the start of the notebook.\n",
    "-   The function reads the file and splits the documents into a list, removing all newlines.\n",
    "-   Furthermore, we replace all HTML entities with their corresponding characters,\n",
    "    -   Note that since we cannot use the html library (as stated in the specification), we manually replace some of the most common HTML entities.\n",
    "-   Finally we remove any empty strings, if they exist, from the list and return the cleaned list of XML documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_xml_docs(file_path):\n",
    "    \"\"\"\n",
    "    Reads and prepares the text file containing XML documents for parsing.\n",
    "    :param file_path: path to assignment text file\n",
    "    :return: list of cleaned XML documents in the text file\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        docs = file.read()\n",
    "\n",
    "    # Split the text file into a list of XML documents and remove the declaration\n",
    "    xml_docs = docs.split('<?xml version=\"1.0\" encoding=\"UTF-8\"?>')[1:]\n",
    "\n",
    "    # Remove all newlines from the text file\n",
    "    xml_docs = [doc.replace('\\n', '') for doc in xml_docs]\n",
    "\n",
    "    # Replace HTML entities with their corresponding characters\n",
    "    html_entities = {'&amp;': '&', '&lt;': '<',\n",
    "                     '&gt;': '>', '&quot;': '\"',\n",
    "                     '&#39;': \"'\", '&#x2018;': \"‘\",\n",
    "                     '&#x2019;': \"’\", '&#xe7;': \"ç\",\n",
    "                     '&#x2013;': \"–\", '&#x2014;': \"—\",\n",
    "                     '&#x201c;': \"“\", '&#x201d;': \"”\"\n",
    "                     }\n",
    "    for entity, char in html_entities.items():\n",
    "        xml_docs = [doc.replace(entity, char) for doc in xml_docs]\n",
    "\n",
    "    # Remove empty strings from the list of XML documents\n",
    "    xml_docs = list(filter(lambda x: len(x.strip()) > 0, xml_docs))\n",
    "\n",
    "    return xml_docs\n",
    "\n",
    "\n",
    "clean_docs = clean_xml_docs(FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "# Print the number of cleaned XML documents\n",
    "print(len(clean_docs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_3_'></a>[Parsing the Data](#toc0_)\n",
    "\n",
    "Here, we extract the information by iterating over the cleaned list of XML documents, using the regular expressions defined in the previous section. We achieve this in the following steps:\n",
    "\n",
    "-   We initialise the empty lists for our attributes.\n",
    "-   Iterate over the cleaned list of XML documents using the compiled regular expressions to extract the information for each attribute.\n",
    "    -   When extracting the information for the `kind` attribute, we use a dictionary to map the values to their corresponding descriptions which were retrieved from the USPTO website. <sup>[5]</sup>\n",
    "-   Append the extracted information to the corresponding list.\n",
    "-   Note that if any of the attributes' values are not found in the XML document, 'NA' is used to represent the absence of the value (helpful for error handling and debugging). We achieve this by:\n",
    "    -   Using try-except blocks to catch the exceptions.\n",
    "    -   For `number_of_citations` (since it has type int), `citations_examiner_counts` and `citations_applicant_counts` we use '0' to represent the absence of the value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise empty lists to store the extracted data before creating the DataFrame\n",
    "grant_ids = []\n",
    "kinds = []\n",
    "patent_titles = []\n",
    "num_claims = []\n",
    "cit_examiner_counts = []\n",
    "cit_applicant_counts = []\n",
    "inventors = []\n",
    "claims_texts = []\n",
    "abstracts = []\n",
    "\n",
    "\n",
    "# Iterate over the list of XML documents and extract the data using compiled regex patterns\n",
    "for doc in clean_docs:\n",
    "    # Extract grant ID\n",
    "    try:\n",
    "        grant_id = GRANT_ID_PATTERN.search(doc).group(1)\n",
    "    except AttributeError:\n",
    "        grant_id = 'NA'\n",
    "    grant_ids.append(grant_id)\n",
    "\n",
    "    # Extract patent kind\n",
    "    try:\n",
    "        kind = KIND_PATTERN.search(doc).group(1)\n",
    "        # Map the codes for kind to their descriptions\n",
    "        kind_map = {\n",
    "            'B2': 'Utility Patent Grant (with a published application) issued on or after January 2, 2001.',\n",
    "            'B1': 'Utility Patent Grant (no published application) issued on or after January 2, 2001.',\n",
    "            'S1': 'Design Patent',\n",
    "            'E1': 'Reissue Patent',\n",
    "            'P1': 'Plant Patent Application published on or after January 2, 2001',\n",
    "            'P2': 'Plant Patent Grant (no published application) issued on or after January 2, 2001',\n",
    "            'P3': 'Plant Patent Grant (with a published application) issued on or after January 2, 2001',\n",
    "        }.get(kind, 'NA')\n",
    "    except AttributeError:\n",
    "        kind = 'NA'\n",
    "        kind_map = 'NA'\n",
    "    kinds.append(kind_map)\n",
    "\n",
    "    # Extract patent title\n",
    "    try:\n",
    "        patent_title = PATENT_TITLE_PATTERN.search(doc).group(1)\n",
    "    except AttributeError:\n",
    "        patent_title = 'NA'\n",
    "    patent_titles.append(patent_title)\n",
    "\n",
    "    # Extract number of claims\n",
    "    try:\n",
    "        num_claim = int(NUMBER_OF_CLAIMS_PATTERN.search(doc).group(1))\n",
    "    except AttributeError:\n",
    "        num_claim = 0\n",
    "    num_claims.append(num_claim)\n",
    "\n",
    "    # Extract number of citations by examiner\n",
    "    try:\n",
    "        citations_examiner_count = len(\n",
    "            CITATIONS_EXAMINER_COUNT_PATTERN.findall(doc))\n",
    "    except TypeError:\n",
    "        citations_examiner_count = 0\n",
    "    cit_examiner_counts.append(citations_examiner_count)\n",
    "\n",
    "    # Extract number of citations by applicant\n",
    "    try:\n",
    "        citations_applicant_count = len(\n",
    "            CITATIONS_APPLICANT_COUNT_PATTERN.findall(doc))\n",
    "    except TypeError:\n",
    "        citations_applicant_count = 0\n",
    "    cit_applicant_counts.append(citations_applicant_count)\n",
    "\n",
    "    # Extract inventor names\n",
    "    inventors_block = INVENTORS_TAG_PATTERN.search(doc)\n",
    "    inventor_list = []\n",
    "    try:\n",
    "        inventor_blocks = INVENTORS_PATTERN.findall(inventors_block.group())\n",
    "        for last, first in inventor_blocks:\n",
    "            inventor_list.append(f\"{first} {last}\")\n",
    "    except:\n",
    "        inventor_list.append('NA')\n",
    "    inventors.append(f\"[{','.join(inventor_list)}]\")\n",
    "\n",
    "    # Extract claims and remove any HTML tags and entities\n",
    "    claim_list = []\n",
    "    try:\n",
    "        claims_block = CLAIMS_TAG_PATTERN.search(doc)\n",
    "        claim_blocks = CLAIMS_TEXT_PATTERN.findall(claims_block.group())\n",
    "        for claim in claim_blocks:\n",
    "            claim = re.sub(r'<[^>]*>|&\\w+;', '', claim)\n",
    "            claim_list.append(claim)\n",
    "    except AttributeError:\n",
    "        claims_texts.append('NA')\n",
    "    claims_texts.append(f\"[{','.join(claim_list)}]\")\n",
    "\n",
    "    # Extract abstracts and remove any HTML tags and entities\n",
    "    abstract_block = ABSTRACT_PATTERN.search(doc)\n",
    "    try:\n",
    "        abstract = abstract_block.group(1)\n",
    "        abstract = re.sub(r'<[^>]*>|&\\w+;', '', abstract)\n",
    "\n",
    "    except AttributeError:\n",
    "        abstract = 'NA'\n",
    "    abstracts.append(abstract)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc5_4_'></a>[Creating a DataFrame](#toc0_)\n",
    "\n",
    "We use the `pandas.DataFrame()` function to create a pandas DataFrame from the lists of extracted data.\n",
    "\n",
    "Finally, we rearrange the columns of the DataFrame to match the order of the attributes in the sample output file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame({\n",
    "    'grant_id': grant_ids,\n",
    "    'kind': kinds,\n",
    "    'patent_title': patent_titles,\n",
    "    'number_of_claims': num_claims,\n",
    "    'citations_examiner_count': cit_examiner_counts,\n",
    "    'citations_applicant_count': cit_applicant_counts,\n",
    "    'inventors': inventors,\n",
    "    'claims_text': claims_texts,\n",
    "    'abstract': abstracts\n",
    "})\n",
    "\n",
    "# Rearrange the columns to match the order in the sample output file\n",
    "df = df[['grant_id', 'patent_title', 'kind', 'number_of_claims', 'inventors',\n",
    "         'citations_applicant_count', 'citations_examiner_count', 'claims_text', 'abstract']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[Outputting Files](#toc0_)\n",
    "\n",
    "Now that we have parsed the text file and created a DataFrame object, we can output the data to CSV and JSON for downstream processing and analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_1_'></a>[Writing to CSV](#toc0_)\n",
    "\n",
    "For outputting the file to CSV we use the `to_csv()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the DataFrame to a CSV file\n",
    "df.to_csv('../data/output/patent_grants.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_2_'></a>[Writing to JSON](#toc0_)\n",
    "\n",
    "For outputting the file to JSON, since we cannot use the `json` library (as stated in the specification), we manually convert the DataFrame object to a JSON formatted string. <sup>[6]</sup>\n",
    "\n",
    "-   We initially set the index of the DataFrame to `grant_id`.\n",
    "-   Convert the DataFrame to a dictionary using the `to_dict()` method, with the `orient` parameter set to `index`.\n",
    "-   This creates a nested dictionary with the `grant_id` as the key and the values as a dictionary of the attributes and their values.\n",
    "-   Using string manipulation we convert the dictionary to a JSON formatted string by iterating over the nested dictionary and concatenating the `key:value` pairs.\n",
    "-   Finally, we write the JSON formatted string to a file using the `write()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set grant_id as index\n",
    "df.set_index('grant_id', inplace=True)\n",
    "\n",
    "# Convert DataFrame to dictionary\n",
    "data = df.to_dict(orient='index')\n",
    "\n",
    "# Convert dictionary to JSON\n",
    "\n",
    "# Initialise JSON string\n",
    "json_data = '{'\n",
    "for i, (key, record) in enumerate(data.items()):\n",
    "    if i > 0:\n",
    "        # Add a comma to separate records\n",
    "        json_data += ',\\n'\n",
    "    json_data += f'\"{key}\": {{'\n",
    "    for key2, value in record.items():\n",
    "        if isinstance(value, str):\n",
    "            # Escape double quotes\n",
    "            value = re.sub('\"', '\\\\\"', value)\n",
    "            # Add double quotes around the value\n",
    "            value = f'\"{value}\"'\n",
    "        # Add the key-value pair to the JSON string\n",
    "        json_data += f'\"{key2}\": {value},'\n",
    "    # Remove the last comma\n",
    "    json_data = json_data[:-1] + '}'\n",
    "# Closing JSON string\n",
    "json_data += '}'\n",
    "\n",
    "# Write JSON to file\n",
    "with open('../data/output/patent_grants.json', 'w') as f:\n",
    "    f.write(json_data)\n",
    "\n",
    "# Reset index to default to allow re-running if required\n",
    "df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc6_3_'></a>[Verifying Outputs](#toc0_)\n",
    "\n",
    "Optionally, we can verify the outputs by loading the CSV and JSON files back into pandas DataFrames.\n",
    "\n",
    "-   This helps us to verify that the outputs can be loaded back into pandas DataFrames without any errors.\n",
    "-   This also helps us to verify that both CSV and JSON outputs have the same format and data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV and JSON files have the same data and format\n"
     ]
    }
   ],
   "source": [
    "# Import the json library for only verifying outputs\n",
    "import json\n",
    "\n",
    "# Load CSV file into a DataFrame\n",
    "df_csv = pd.read_csv('../data/output/patent_grants.csv', keep_default_na=False)\n",
    "\n",
    "# Load JSON file into a dictionary\n",
    "with open('../data/output/patent_grants.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df_json = pd.DataFrame.from_dict(json_data, orient='index')\n",
    "\n",
    "# Set grant_id as index\n",
    "df_json.index.name = 'grant_id'\n",
    "df_json.reset_index(inplace=True)\n",
    "\n",
    "# Check for similarities between the CSV and JSON files\n",
    "if set(df_csv.columns) != set(df_json.columns):\n",
    "    print('Error: CSV and JSON files DO NOT have the same columns')\n",
    "else:\n",
    "    if df_csv.equals(df_json):\n",
    "        print('CSV and JSON files have the same data and format')\n",
    "    else:\n",
    "        print('Error: CSV and JSON files DO NOT have the same data and format')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[Summary](#toc0_)\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "-   Examined the Patent Files dataset and explored patterns that correspond to the attributes we want to extract.\n",
    "-   Identified the regular expressions required to extract the information from the text file for each of the attributes.\n",
    "-   Prepared the data by cleaning the text file and splitting it into a list of XML documents.\n",
    "-   Parsed the data by iterating over the cleaned list of XML documents, using the compiled regular expressions.\n",
    "-   And finally, outputted the data to CSV and JSON files for further downstream processing analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc8_'></a>[References](#toc0_)\n",
    "\n",
    "[1] [Formatting Patent Numbers](https://web.cas.org/training/stneasytips/patentnumber2.html)\n",
    "\n",
    "[2] [USPTO - Patent Numbers](https://www.uspto.gov/patents/apply/applying-online/patent-number)\n",
    "\n",
    "[3] [\"Kind Codes\" Included on USPTO Patent Documents](https://manuals.ipaustralia.gov.au/patent/annex-z---uspto-kind-codes)\n",
    "\n",
    "[4] [PEP 8 – Style Guide for Python Code - Constants](https://peps.python.org/pep-0008/#constants)\n",
    "\n",
    "[5] [U.S. Patent Grant Data XML](https://www.uspto.gov/sites/default/files/products/PatentGrantXMLv42-Documentation-508.pdf)\n",
    "\n",
    "[6] [Stackoverflow, Generating JSON without json library](https://stackoverflow.com/questions/19712133/creating-json-in-python-without-using-json-import)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
